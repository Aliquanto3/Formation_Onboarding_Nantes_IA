{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe4b60a",
   "metadata": {},
   "source": [
    "# Atelier pratique‚ÄØ: Comprendre l‚ÄôIA par la pratique\n",
    "*Version mise √† jour ‚Äì 20 Mai 2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a440f7",
   "metadata": {},
   "source": [
    "Ce notebook a √©t√© pens√© pour des **d√©butants complets**‚ÄØ: chaque cellule de code est abondamment comment√©e et peut √™tre ex√©cut√©e pas¬†√†¬†pas.  \n",
    "S‚Äôil s‚Äôagit de votre **premier contact avec Python**, suivez simplement ces trois r√®gles¬†:\n",
    "\n",
    "1. Cliquez sur la cellule (elle est entour√©e d‚Äôun cadre bleu).  \n",
    "2. Appuyez sur le bouton ‚ñ∂Ô∏è (*Run*) ou sur **Shift‚ÄØ+‚ÄØEnter** pour l‚Äôex√©cuter.  \n",
    "3. Observez le r√©sultat qui appara√Æt juste en dessous.\n",
    "\n",
    "> **Important¬†:** si vous ex√©cutez ce notebook **localement** (VS¬†Code, Jupyter‚Ä¶), assurez‚Äëvous d‚Äôabord d‚Äôinstaller les librairies n√©cessaires¬†:  \n",
    "> `pip install scikit-learn matplotlib numpy tensorflow-cpu transformers`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb08e59",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Classification supervis√©e ‚Äì jeu de donn√©es *Iris*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f829d67",
   "metadata": {},
   "source": [
    "### ‚û°Ô∏è √Ä tester  \n",
    "1. Changez `test_size` √† **0.4** ou **0.1** pour observer l‚Äôimpact sur la pr√©cision.  \n",
    "2. Remplacez `LogisticRegression` par `DecisionTreeClassifier` (√† importer depuis `sklearn.tree`) puis r√©‚Äëex√©cutez.  \n",
    "3. Modifiez `random_state` (graine al√©atoire)¬†: le d√©coupage change, la pr√©cision aussi.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723cd36",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ R√©seau de neurones de base avec Keras/TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf81447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Importations\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# üß† D√©finition de l'architecture du r√©seau\n",
    "# - input_shape=(4,) car chaque fleur = 4 chiffres\n",
    "# - 1 couche cach√©e de 16 neurones (Dense) avec fonction d'activation ReLU\n",
    "# - sortie Dense(3) car 3 esp√®ces, activation softmax -> probas qui se somment √† 1\n",
    "model = models.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# üß† Compilation¬†: on choisit comment apprendre\n",
    "model.compile(\n",
    "    optimizer='adam',                          # m√©thode de descente de gradient\n",
    "    loss='sparse_categorical_crossentropy',    # ad√©quat pour plusieurs classes\n",
    "    metrics=['accuracy']                       # on suit l'accuracy\n",
    ")\n",
    "\n",
    "# üß† Apprentissage\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,             # 50 passes sur les donn√©es\n",
    "    batch_size=16,         # nombre d'exemples vus avant mise √† jour des poids\n",
    "    verbose=0,             # 0 = silencieux, 1 = barre de progression\n",
    "    validation_split=0.2   # 20¬†% du train sert √† valider (d√©tecter overfitting)\n",
    ")\n",
    "\n",
    "# üß† Visualisation de la courbe d'apprentissage\n",
    "plt.plot(history.history['accuracy'], label='Train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Apprentissage du r√©seau de neurones')\n",
    "plt.show()\n",
    "\n",
    "# üß† √âvaluation finale sur le jeu de test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Pr√©cision sur le test¬†: {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b7e6a",
   "metadata": {},
   "source": [
    "### ‚û°Ô∏è √Ä tester  \n",
    "* **Complexit√© du r√©seau¬†:** ajoutez une seconde couche Dense, ou augmentez le nombre d‚Äôunit√©s (ex¬†: 32).  \n",
    "* **Fonction d‚Äôactivation¬†:** essayez `tanh` ou `elu` √† la place de `relu`.  \n",
    "* **Nombre d‚Äôepochs¬†:** mettez 200 et observez si le mod√®le **sur‚Äëapprend** (la courbe validation diverge).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2f8d4",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ G√©n√©ration de texte (LLM open source GPT‚Äë2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úçÔ∏è Importer un pipeline de g√©n√©ration depuis HuggingFace Transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# Le mod√®le GPT‚Äë2 (124¬†M param√®tres) tient dans 500‚ÄØMB ‚Äì raisonnable pour un atelier\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "prompt = \"Dans le futur,\"  # phrase de d√©part\n",
    "resultats = generator(prompt, max_length=40, num_return_sequences=1)\n",
    "\n",
    "print(\"\\n--- Texte g√©n√©r√© ---\\n\")\n",
    "print(resultats[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a324fc",
   "metadata": {},
   "source": [
    "> **Note s√©curit√©/√©thique¬†:** GPT‚Äë2 est open‚Äësource et non filtr√©‚ÄØ; il peut produire du contenu inexact ou inappropri√©. N‚Äôutilisez jamais les sorties sans relecture humaine.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7683d",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ (Bonus) Biais et √©quit√© ‚Äì mini‚Äësimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2938d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# üé≤ G√©n√©rons un jeu de donn√©es *biais√©*\n",
    "np.random.seed(0)\n",
    "n = 200\n",
    "\n",
    "# sensitive_attribute = appartenance √† un groupe (0 ou 1)\n",
    "sensitive_attribute = np.random.randint(0, 2, size=n)\n",
    "\n",
    "# feature = caract√©ristique 'm√©ritocratique'\n",
    "feature = np.random.randn(n)\n",
    "\n",
    "# label = d√©cision d'embauche (1) ou refus (0); \n",
    "# le groupe 1 a +0.5 point d'avantage -> biais dans la *r√©alit√©*\n",
    "label = (feature + sensitive_attribute * 0.5 > 0).astype(int)\n",
    "\n",
    "X = feature.reshape(-1, 1)\n",
    "y = label\n",
    "\n",
    "# ‚öñÔ∏è Mod√®le na√Øf qui ignore la variable sensible\n",
    "clf = LogisticRegression().fit(X, y)\n",
    "pred = clf.predict(X)\n",
    "\n",
    "# ‚öñÔ∏è √âquit√©¬†: comparons la balanced_accuracy par groupe\n",
    "for group in [0, 1]:\n",
    "    idx = sensitive_attribute == group\n",
    "    acc = balanced_accuracy_score(y[idx], pred[idx])\n",
    "    print(f\"Groupe {group} ‚Äì balanced accuracy¬†: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42335d39",
   "metadata": {},
   "source": [
    "Vous devriez constater que le mod√®le **n‚Äôefface pas** le biais d‚Äôorigine¬†; au contraire il peut le renforcer.  \n",
    "üëâ Conclusion‚ÄØ: √©valuer un mod√®le seulement sur une m√©trique globale peut masquer des discriminations.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
