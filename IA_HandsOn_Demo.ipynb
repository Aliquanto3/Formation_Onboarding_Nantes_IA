{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe4b60a",
   "metadata": {},
   "source": [
    "# Atelier pratique : Comprendre l’IA par la pratique\n",
    "*Version mise à jour – 20 May 2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a440f7",
   "metadata": {},
   "source": [
    "Ce notebook a été pensé pour des **débutants complets** : chaque cellule de code est abondamment commentée et peut être exécutée pas à pas.  \n",
    "S’il s’agit de votre **premier contact avec Python**, suivez simplement ces trois règles :\n",
    "\n",
    "1. Cliquez sur la cellule (elle est entourée d’un cadre bleu).  \n",
    "2. Appuyez sur le bouton ▶️ (*Run*) ou sur **Shift + Enter** pour l’exécuter.  \n",
    "3. Observez le résultat qui apparaît juste en dessous.\n",
    "\n",
    "> **Important :** si vous exécutez ce notebook **localement** (VS Code, Jupyter…), assurez‑vous d’abord d’installer les librairies nécessaires :  \n",
    "> `pip install scikit-learn matplotlib numpy tensorflow-cpu transformers`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb08e59",
   "metadata": {},
   "source": [
    "## 1️⃣ Classification supervisée – jeu de données *Iris*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aad6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔶 Étape 1 : importations\n",
    "# La librairie scikit‑learn contient des jeux de données et des algorithmes \"prêt à l'emploi\".\n",
    "from sklearn import datasets                       # jeux de données jouets\n",
    "from sklearn.model_selection import train_test_split # découpe aléatoire train/test\n",
    "from sklearn.linear_model import LogisticRegression  # algorithme de régression logistique\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt                     # affichage de graphes\n",
    "import numpy as np                                  # calcul numérique\n",
    "\n",
    "# 🔶 Étape 2 : chargement du jeu de données\n",
    "iris = datasets.load_iris()  # 150 fleurs, 4 mesures, 3 espèces\n",
    "X, y = iris.data, iris.target  # X = caractéristiques, y = étiquettes\n",
    "\n",
    "print(f\"Taille du jeu de données : {X.shape[0]} échantillons × {X.shape[1]} caractéristiques\")\n",
    "\n",
    "# 🔶 Étape 3 : séparation en apprentissage (75 %) et test (25 %)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y)  # stratify garantit les mêmes proportions d'espèces\n",
    "\n",
    "# 🔶 Étape 4 : création et entraînement du modèle\n",
    "clf = LogisticRegression(max_iter=200)  # 200 itérations max\n",
    "clf.fit(X_train, y_train)               # \"apprendre\" = ajuster les paramètres sur les données d'entraînement\n",
    "\n",
    "# 🔶 Étape 5 : évaluation sur les données jamais vues (test)\n",
    "y_pred = clf.predict(X_test)            # prédiction de l'espèce\n",
    "acc = accuracy_score(y_test, y_pred)    # proportion de bonnes réponses\n",
    "print(f\"Précision (accuracy) : {acc:.2f}\")\n",
    "\n",
    "# 🔶 Étape 6 : matrice de confusion (visualise les erreurs)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Blues')\n",
    "plt.title('Matrice de confusion – Iris')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f829d67",
   "metadata": {},
   "source": [
    "### ➡️ À tester  \n",
    "1. Changez `test_size` à **0.4** ou **0.1** pour observer l’impact sur la précision.  \n",
    "2. Remplacez `LogisticRegression` par `DecisionTreeClassifier` (à importer depuis `sklearn.tree`) puis ré‑exécutez.  \n",
    "3. Modifiez `random_state` (graine aléatoire) : le découpage change, la précision aussi.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723cd36",
   "metadata": {},
   "source": [
    "## 2️⃣ Réseau de neurones de base avec Keras/TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf81447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Importations\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 🧠 Définition de l'architecture du réseau\n",
    "# - input_shape=(4,) car chaque fleur = 4 chiffres\n",
    "# - 1 couche cachée de 16 neurones (Dense) avec fonction d'activation ReLU\n",
    "# - sortie Dense(3) car 3 espèces, activation softmax -> probas qui se somment à 1\n",
    "model = models.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# 🧠 Compilation : on choisit comment apprendre\n",
    "model.compile(\n",
    "    optimizer='adam',                          # méthode de descente de gradient\n",
    "    loss='sparse_categorical_crossentropy',    # adéquat pour plusieurs classes\n",
    "    metrics=['accuracy']                       # on suit l'accuracy\n",
    ")\n",
    "\n",
    "# 🧠 Apprentissage\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,             # 50 passes sur les données\n",
    "    batch_size=16,         # nombre d'exemples vus avant mise à jour des poids\n",
    "    verbose=0,             # 0 = silencieux, 1 = barre de progression\n",
    "    validation_split=0.2   # 20 % du train sert à valider (détecter overfitting)\n",
    ")\n",
    "\n",
    "# 🧠 Visualisation de la courbe d'apprentissage\n",
    "plt.plot(history.history['accuracy'], label='Train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Apprentissage du réseau de neurones')\n",
    "plt.show()\n",
    "\n",
    "# 🧠 Évaluation finale sur le jeu de test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Précision sur le test : {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b7e6a",
   "metadata": {},
   "source": [
    "### ➡️ À tester  \n",
    "* **Complexité du réseau :** ajoutez une seconde couche Dense, ou augmentez le nombre d’unités (ex : 32).  \n",
    "* **Fonction d’activation :** essayez `tanh` ou `elu` à la place de `relu`.  \n",
    "* **Nombre d’epochs :** mettez 200 et observez si le modèle **sur‑apprend** (la courbe validation diverge).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2f8d4",
   "metadata": {},
   "source": [
    "## 3️⃣ Génération de texte (LLM open source GPT‑2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍️ Importer un pipeline de génération depuis HuggingFace Transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# Le modèle GPT‑2 (124 M paramètres) tient dans 500 MB – raisonnable pour un atelier\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "prompt = \"Dans le futur,\"  # phrase de départ\n",
    "resultats = generator(prompt, max_length=40, num_return_sequences=1)\n",
    "\n",
    "print(\"\\n--- Texte généré ---\\n\")\n",
    "print(resultats[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a324fc",
   "metadata": {},
   "source": [
    "> **Note sécurité/éthique :** GPT‑2 est open‑source et non filtré ; il peut produire du contenu inexact ou inapproprié. N’utilisez jamais les sorties sans relecture humaine.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7683d",
   "metadata": {},
   "source": [
    "## 4️⃣ (Bonus) Biais et équité – mini‑simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2938d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# 🎲 Générons un jeu de données *biaisé*\n",
    "np.random.seed(0)\n",
    "n = 200\n",
    "\n",
    "# sensitive_attribute = appartenance à un groupe (0 ou 1)\n",
    "sensitive_attribute = np.random.randint(0, 2, size=n)\n",
    "\n",
    "# feature = caractéristique 'méritocratique'\n",
    "feature = np.random.randn(n)\n",
    "\n",
    "# label = décision d'embauche (1) ou refus (0); \n",
    "# le groupe 1 a +0.5 point d'avantage -> biais dans la *réalité*\n",
    "label = (feature + sensitive_attribute * 0.5 > 0).astype(int)\n",
    "\n",
    "X = feature.reshape(-1, 1)\n",
    "y = label\n",
    "\n",
    "# ⚖️ Modèle naïf qui ignore la variable sensible\n",
    "clf = LogisticRegression().fit(X, y)\n",
    "pred = clf.predict(X)\n",
    "\n",
    "# ⚖️ Équité : comparons la balanced_accuracy par groupe\n",
    "for group in [0, 1]:\n",
    "    idx = sensitive_attribute == group\n",
    "    acc = balanced_accuracy_score(y[idx], pred[idx])\n",
    "    print(f\"Groupe {group} – balanced accuracy : {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42335d39",
   "metadata": {},
   "source": [
    "Vous devriez constater que le modèle **n’efface pas** le biais d’origine ; au contraire il peut le renforcer.  \n",
    "👉 Conclusion : évaluer un modèle seulement sur une métrique globale peut masquer des discriminations.  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
