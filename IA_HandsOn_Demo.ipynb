{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe4b60a",
   "metadata": {},
   "source": [
    "# Atelier pratiqueâ€¯: Comprendre lâ€™IA par la pratique\n",
    "*Version mise Ã  jour â€“ 20 May 2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a440f7",
   "metadata": {},
   "source": [
    "Ce notebook a Ã©tÃ© pensÃ© pour des **dÃ©butants complets**â€¯: chaque cellule de code est abondamment commentÃ©e et peut Ãªtre exÃ©cutÃ©e pasÂ Ã Â pas.  \n",
    "Sâ€™il sâ€™agit de votre **premier contact avec Python**, suivez simplement ces trois rÃ¨glesÂ :\n",
    "\n",
    "1. Cliquez sur la cellule (elle est entourÃ©e dâ€™un cadre bleu).  \n",
    "2. Appuyez sur le bouton â–¶ï¸ (*Run*) ou sur **Shiftâ€¯+â€¯Enter** pour lâ€™exÃ©cuter.  \n",
    "3. Observez le rÃ©sultat qui apparaÃ®t juste en dessous.\n",
    "\n",
    "> **ImportantÂ :** si vous exÃ©cutez ce notebook **localement** (VSÂ Code, Jupyterâ€¦), assurezâ€‘vous dâ€™abord dâ€™installer les librairies nÃ©cessairesÂ :  \n",
    "> `pip install scikit-learn matplotlib numpy tensorflow-cpu transformers`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb08e59",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Classification supervisÃ©e â€“ jeu de donnÃ©es *Iris*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aad6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¶ Ã‰tape 1Â : importations\n",
    "# La librairie scikitâ€‘learn contient des jeux de donnÃ©es et des algorithmes \"prÃªt Ã  l'emploi\".\n",
    "from sklearn import datasets                       # jeux de donnÃ©es jouets\n",
    "from sklearn.model_selection import train_test_split # dÃ©coupe alÃ©atoire train/test\n",
    "from sklearn.linear_model import LogisticRegression  # algorithme de rÃ©gression logistique\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt                     # affichage de graphes\n",
    "import numpy as np                                  # calcul numÃ©rique\n",
    "\n",
    "# ğŸ”¶ Ã‰tape 2Â : chargement du jeu de donnÃ©es\n",
    "iris = datasets.load_iris()  # 150 fleurs, 4 mesures, 3 espÃ¨ces\n",
    "X, y = iris.data, iris.target  # X = caractÃ©ristiques, y = Ã©tiquettes\n",
    "\n",
    "print(f\"Taille du jeu de donnÃ©esÂ : {X.shape[0]} Ã©chantillons Ã— {X.shape[1]} caractÃ©ristiques\")\n",
    "\n",
    "# ğŸ”¶ Ã‰tape 3Â : sÃ©paration en apprentissage (75Â %) et test (25Â %)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y)  # stratify garantit les mÃªmes proportions d'espÃ¨ces\n",
    "\n",
    "# ğŸ”¶ Ã‰tape 4Â : crÃ©ation et entraÃ®nement du modÃ¨le\n",
    "clf = LogisticRegression(max_iter=200)  # 200 itÃ©rations max\n",
    "clf.fit(X_train, y_train)               # \"apprendre\" = ajuster les paramÃ¨tres sur les donnÃ©es d'entraÃ®nement\n",
    "\n",
    "# ğŸ”¶ Ã‰tape 5Â : Ã©valuation sur les donnÃ©es jamais vues (test)\n",
    "y_pred = clf.predict(X_test)            # prÃ©diction de l'espÃ¨ce\n",
    "acc = accuracy_score(y_test, y_pred)    # proportion de bonnes rÃ©ponses\n",
    "print(f\"PrÃ©cision (accuracy)Â : {acc:.2f}\")\n",
    "\n",
    "# ğŸ”¶ Ã‰tape 6Â : matrice de confusion (visualise les erreurs)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Blues')\n",
    "plt.title('Matrice de confusion â€“ Iris')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f829d67",
   "metadata": {},
   "source": [
    "### â¡ï¸ Ã€ tester  \n",
    "1. Changez `test_size` Ã  **0.4** ou **0.1** pour observer lâ€™impact sur la prÃ©cision.  \n",
    "2. Remplacez `LogisticRegression` par `DecisionTreeClassifier` (Ã  importer depuis `sklearn.tree`) puis rÃ©â€‘exÃ©cutez.  \n",
    "3. Modifiez `random_state` (graine alÃ©atoire)Â : le dÃ©coupage change, la prÃ©cision aussi.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723cd36",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ RÃ©seau de neurones de base avec Keras/TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf81447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  Importations\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ğŸ§  DÃ©finition de l'architecture du rÃ©seau\n",
    "# - input_shape=(4,) car chaque fleur = 4 chiffres\n",
    "# - 1 couche cachÃ©e de 16 neurones (Dense) avec fonction d'activation ReLU\n",
    "# - sortie Dense(3) car 3 espÃ¨ces, activation softmax -> probas qui se somment Ã  1\n",
    "model = models.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# ğŸ§  CompilationÂ : on choisit comment apprendre\n",
    "model.compile(\n",
    "    optimizer='adam',                          # mÃ©thode de descente de gradient\n",
    "    loss='sparse_categorical_crossentropy',    # adÃ©quat pour plusieurs classes\n",
    "    metrics=['accuracy']                       # on suit l'accuracy\n",
    ")\n",
    "\n",
    "# ğŸ§  Apprentissage\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,             # 50 passes sur les donnÃ©es\n",
    "    batch_size=16,         # nombre d'exemples vus avant mise Ã  jour des poids\n",
    "    verbose=0,             # 0 = silencieux, 1 = barre de progression\n",
    "    validation_split=0.2   # 20Â % du train sert Ã  valider (dÃ©tecter overfitting)\n",
    ")\n",
    "\n",
    "# ğŸ§  Visualisation de la courbe d'apprentissage\n",
    "plt.plot(history.history['accuracy'], label='Train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Apprentissage du rÃ©seau de neurones')\n",
    "plt.show()\n",
    "\n",
    "# ğŸ§  Ã‰valuation finale sur le jeu de test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"PrÃ©cision sur le testÂ : {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b7e6a",
   "metadata": {},
   "source": [
    "### â¡ï¸ Ã€ tester  \n",
    "* **ComplexitÃ© du rÃ©seauÂ :** ajoutez une seconde couche Dense, ou augmentez le nombre dâ€™unitÃ©s (exÂ : 32).  \n",
    "* **Fonction dâ€™activationÂ :** essayez `tanh` ou `elu` Ã  la place de `relu`.  \n",
    "* **Nombre dâ€™epochsÂ :** mettez 200 et observez si le modÃ¨le **surâ€‘apprend** (la courbe validation diverge).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2f8d4",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ GÃ©nÃ©ration de texte (LLM open source GPTâ€‘2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœï¸ Importer un pipeline de gÃ©nÃ©ration depuis HuggingFace Transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# Le modÃ¨le GPTâ€‘2 (124Â M paramÃ¨tres) tient dans 500â€¯MB â€“ raisonnable pour un atelier\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "prompt = \"Dans le futur,\"  # phrase de dÃ©part\n",
    "resultats = generator(prompt, max_length=40, num_return_sequences=1)\n",
    "\n",
    "print(\"\\n--- Texte gÃ©nÃ©rÃ© ---\\n\")\n",
    "print(resultats[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a324fc",
   "metadata": {},
   "source": [
    "> **Note sÃ©curitÃ©/Ã©thiqueÂ :** GPTâ€‘2 est openâ€‘source et non filtrÃ©â€¯; il peut produire du contenu inexact ou inappropriÃ©. Nâ€™utilisez jamais les sorties sans relecture humaine.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7683d",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ (Bonus) Biais et Ã©quitÃ© â€“ miniâ€‘simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2938d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# ğŸ² GÃ©nÃ©rons un jeu de donnÃ©es *biaisÃ©*\n",
    "np.random.seed(0)\n",
    "n = 200\n",
    "\n",
    "# sensitive_attribute = appartenance Ã  un groupe (0 ou 1)\n",
    "sensitive_attribute = np.random.randint(0, 2, size=n)\n",
    "\n",
    "# feature = caractÃ©ristique 'mÃ©ritocratique'\n",
    "feature = np.random.randn(n)\n",
    "\n",
    "# label = dÃ©cision d'embauche (1) ou refus (0); \n",
    "# le groupe 1 a +0.5 point d'avantage -> biais dans la *rÃ©alitÃ©*\n",
    "label = (feature + sensitive_attribute * 0.5 > 0).astype(int)\n",
    "\n",
    "X = feature.reshape(-1, 1)\n",
    "y = label\n",
    "\n",
    "# âš–ï¸ ModÃ¨le naÃ¯f qui ignore la variable sensible\n",
    "clf = LogisticRegression().fit(X, y)\n",
    "pred = clf.predict(X)\n",
    "\n",
    "# âš–ï¸ Ã‰quitÃ©Â : comparons la balanced_accuracy par groupe\n",
    "for group in [0, 1]:\n",
    "    idx = sensitive_attribute == group\n",
    "    acc = balanced_accuracy_score(y[idx], pred[idx])\n",
    "    print(f\"Groupe {group} â€“ balanced accuracyÂ : {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42335d39",
   "metadata": {},
   "source": [
    "Vous devriez constater que le modÃ¨le **nâ€™efface pas** le biais dâ€™origineÂ ; au contraire il peut le renforcer.  \n",
    "ğŸ‘‰ Conclusionâ€¯: Ã©valuer un modÃ¨le seulement sur une mÃ©trique globale peut masquer des discriminations.  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
